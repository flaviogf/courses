#+TITLE: Elasticsearch guide
#+AUTHOR: flaviogf
#+DATE: [2022-10-02 Sun]

* Objectives
+ Install, configure, and administer an Elasticsearch cluster
+ Index your data, optimize your indices, and search with the Elasticsearch query language
+ Discover trends, patterns, and anomalies with aggregation and the machine learning APIs

* What is Elasticsearch?
+ For search and analysis
+ Elasticsearch is the distributed search and analytics engine at the heart of the Elastic Stack
+ Kibana enables you to interactively explore, visualize, and share insightes into your data and manage and monitor the stack
+ Elasticsearch is where the indexing, search and analysis magic happens
+ Elasticsearch provides near real-time search and analytics for all types of data
+ Structured text
+ Unstructured text
+ Numerical data
+ Geospatial data
+ While not every problem is a search problem, Elasticsearch offers speed and flexibility to handle data in a wide variety of use cases:
  - Add a search box to an app or website
  - Store and analyze logs, metrics, and security event data
  - Use machine learning to automatically model the behavior of your data in real time
  - Automate business workflow using Elasticsearch as a storage engine
  - Manage, integrate, and analyze spatial information using Elasticsearch as a geographic information system (GIS)
  - Store and process genetic data using Elasticsearch as a bioinformatics research tool

** Data in: documents and indices
+ Distributed document store
+ Does not store rows of columnar data
+ Stores complex data structures that have been serialized as JSON documents
+ Stored documents are distributed across the cluster
+ And can be accessed immediately from any node
+ When a document is stored, it is indexed and fully searchable in near real-time--within 1 second
+ Elasticsearch uses a data structure called inverted index
+ It supports very fat full-text searches
+ An inverted index lists every unique word that appears in any document, and identifies all of the documents each word occurs in
+ An index is like an optimized collection of documents
+ And each document is a collection of fields
+ By default, Elasticsearch indexes all data in every field
+ And each indexed field has a dedicated, optimized data structure
+ For example
  - Text fields are stored in inverted indices
  - Numeric and geo fields are stored in BKD trees
+ The ability to use the per-field data strucutres to assembe and return search result is what makes Elasticsearch so fast
+ Elasticsearch also has the ability to be schema-less
+ When dynamic mapping is enabled, Elasticsearch automatically detects and adds new fields to the index
+ This default behavior makes it easy to index and explore your data
+ Defining your own mappings enable you to
  - Distinguish between full-text string fields and exact value string fields
  - Perform language-specific text analysis
  - Optimize fields for partial matching
  - Use custom date formats
  - Use data types sucha as geo_point and geo_shape that canoot be automatically detected
+ It's often useful to index the same field in different ways for different purposes
+ For example
  - Index a string field as both a text field for full-text search and as a keyword field for sorting or aggregation

** Information out: search and analyze
+ While you can use Elasticsearch as a document store and retrieve documents and their metadata
+ The real power comes from being able to easily access the full suite of search capabilities built on the Apache Lucene search engine library
+ Elasticsearch provides a simple, coherent REST API for managing your clusters, and indexing and searching your data
+ For testing purposes you can easily submit requests directly from the command line or trough the Developer Console in Kibana
+ From your applications you can use the Elasticsearch client for your language of choice: Java, Javascript, Go, .NET, PHP, Per, Python or Ruby
+ Searching your data
+ The Elasticsearch REST APIs support
  - Structured queries
  - Full text queries
  - Complex queries that combine the two
+ Structured queries are similar to the types of queries you can construct in SQL
+ You could search the gender and age fields in your employee index and sort the matches by the hire_date field
+ Full-text queries find all documents that match the query string and return them sorted by relevance
+ Relevance is how good a match they are for your search terms
+ In addition to searching for individual terms, you can perform
  - Phrase searches
  - Similarity searches
  - Prefix searches
+ And get autocomplete suggestions
+ Elasticsearch indexes non-textual data in optimized data structures that support high-performance geo and numerical queries
+ You can access all of these search capabilities using Elasticsearch's comprehensive JSON-style query language (Query DSL)
+ You can also construct SQL-style queries to search and aggregate data natively inside Elasticsearch, and JDBC and OBDC drives enable a broad range of thirdy-party applications to interact with Elasticsearch via SQL
+ Analyzing your data
+ Elasticsearch aggregations enable you to build complex summaries of your data and gain insight into key metrics, patterns, and trends
+ Aggregations enable you to answer questions like
  - How many needles are in the haystack?
  - What is the average length of the needles?
  - What is te median length of the needles, broken down by manufacturer?
  - How many needles were added to the haystack in each of the last six months?
+ You can also use aggregations to answer more subtle questions, such as
  - What are your most popular needle manufacturer?
  - Are there any unusual or anamalous clumps of needles?
+ Because aggregations leverage the same data-structures used for search, they are also very fast
+ Aggregations operate alongside search requests
+ You can search documents, filter results, and perform analytics at the same time, on the same data, in a single request
+ Aggregations are calculated in the context of a particular search
+ You cant use machine learning features to create accurate baselines of normal behavior in your data and identify anomalous patterns
+ With machine learning, you cant detect
  - Anomalies related to temporal deviations in values, counts, or frequencies
  - Statistical rarity
  - Unusual behaviors for a member of a population

** Scalability and resilience: clusters, nodes, and shards
+ Elasticsearch is built to be always available and to scale with your needs
+ It does so by being distributed by nature
+ You can add servers (nodes) to a cluster to increase capacity and Elasticsearch automatically distributes your data and query load across all of the available nodes
+ Elasticsearch knows how to balance multi-node clusters to provide scale and high availability
+ Under the covers, an Elasticsearch index is really just a grouping of one or more physical shards
+ Where each shard is actually a self-contained index
+ Elasticsearch distributes the documents in an index across multiple shards, and those shards across multiple nodes
+ By doing so Elasticsearch can ensure redundancy, which both protects agains hardware failures and increase query capacity as nodes are added to a cluster
+ As the cluster grows (or shrinks), Elasticsearch automatically migrates shards to rebalance the cluster
+ There are two types of shards
  - Primaries
  - Replicas
+ Each document in an index belongs to one primary shard
+ A replica shard is a copy of a primary shard
+ Replicas provide redundant copies of your data
+ The number of primary shards in an index is fixed at the time that an index is created
+ The number of replicas shards can be changed at any time, without interrupting indexing or query operations
+ There are a number of performance considerations and trade offs with respecto to shard size and the number of primary shards configured to an index
+ The more shards, the more overhead there is simply in maintaining those indices
+ The larger the shard size, the longer it takes to move shards around when Elasticsearch needs to rebalance a cluster
+ Querying lots of small shards makes the processing per shard faster, but more queries mean overhead, so querying a smaller number of larger shards might be faster
+ As a starting point
  - Aim to keep the average shard size between a few GB and a few tens of GB. For use cases with time-based data, it is common to see shards in the 20GB to 40GB range
  - Avoid the gazillion shards problem. The number of shards a node can hold is proportional to the available heap space. As a general rule, the number of shards per GB of heap space should be leass than 20
+ The best way to determine the optimal configuration for your use case is through testing with your own data and queries
+ In case of disaster
+ A cluster's nodes need good, reliable connections to each other
+ To probide better connections, you typically co-locate the nodes in the same data center or nearby data centers
+ However, to maintain high availability, you also need to avoid any single point of failure
+ To solve both problems the answer is Cross-cluster replication (CCR)
+ CCR provides a way to automatically synchronize indices from your primary cluster to a secondary remote cluster that can serve as a hot backup
+ You can also use CCR to create secondary clusters to serve read requests in geo-proximity to your users
+ Cross-cluster replication is active-passive
+ The index on the primary cluster is the active leader index and handles all write requests
+ Indices replicated to secondary clusters are read-only followers

* Set up Elasticsearch
+ Downloading
+ Installing
+ Starting
+ Configuring
+ Supported platforms
+ Elasticsearch is built using Java
+ Elasticsearch includes a bundled version of OpenJDK
+ The bundled JVM is the recommended JVM and is located within the jdk direcotry of the Elasticsearch home directory
+ To use your own version of JAVA, set the ES_JAVA_HOME environment variable
+ The recommend versions is the LTS
+ Elasticsearch will refuse to start if a known-bad version of Java is used
+ Use dedicated hosts
+ In production the recommend is to run Elasticsearch on a dedicated host or as a primary service
+ Several Elasticsearch features, such as automatica JVM heap sizing, assume it's the only resource-intesive application on the host or container
+ For example, you might run Meticbeat alongised Elasticsearch for cluster statistics, but a resource-heavy Logstash deployment should be on its own host
*** Installing Elasticsearch
+ Elastic cloud offers all of the features of Elasticsearch, Kibana, and Elastic's Observability
+ Self-manage Elasticsearch options
+ You can
  - Run Elasticsearch on any Linux, MacOS, or Windows machine
  - Run Elasticsearch in a Docker container
  - Set up and manage Elasticsearch, Kibana, Elastic Agent, and the rest of the Elastic Stack on Kubernetes with Elastic Cloud on Kubernetes
  - Locally is recommended to run Elasticsearch using Docker and running both Elasticsearch and Kibana
+ Elasticsearch install packages
**** Install Elasticsearch with docker
+ Elasticsearch is available as Docker images at www.docker.elastic.co
+ This package contians both free and subscription features
+ Starting in Elasticsearch 8.0, security is enabled by default. With security enabled, Elastic Stack security features require TLS encryption for the transport networking layer, or your cluster will fail to start
+ Install Docker Desktop or Docker Engine
+ At least 4Gib of memory is required
+ Pull Elasticsearch Docker image

#+begin_src bash
  docker pull docker.elastic.co/elasticsearch/elasticsearch:8.4.3
#+end_src

+ With Elasticsearch Docker image locally you can start a single-node or multi-node cluster
+ Start a single-node cluster with Docker
+ When starting a single-node Elasticsearch cluster in a Docker container, the following security configuration ocrrus automatically
  - Certificates and keys are generated for the transport and HTTP layers
  - The TLS configuration settings are written to elasticsearch.yml
  - A password is generated for the elastic user
  - An enrollment token is generated for kibana
+ The enrollment token is valid for 30 minutes
+ This token automatically applies the security settings from your Elasticsearch cluster, authenticates to Elasticsearch with the kibana_system user, and writes the security configuration to kibana.yml
+ Starting a single-node Elasticsearch cluster for development or testing
  1. Create a new docker network for Elasticsearch and kibana

     #+begin_src bash
       docker network create elastic
     #+end_src

  2. Start Elasticsearch in Docker. A password is generated for the elastic user and output to the terminal, plus an enrollment token for enrolling Kibana

     #+begin_src bash
       docker run --name es01 --net elastic -p 9200:9200 -p 9300:9300 -it docker.elastic.co/elasticsearch/elasticsearch:8.4.3
     #+end_src

  3. Copy the generated password and enrollment token and save them in a secure location
     These values are shown only when you start Elasticsearch for the first time

     If you need to reset the password for a specif user, run the elasticsearch-reset-password tool. This tool is available in the Elasticsearch /bin directory of the Docker container

     #+begin_src bash
       docker exec -it es01 /usr/share/elasticsearch/bin/elasticsearc-reset-password
     #+end_src

  4. Copy the http_ca.crt security certificate from your Docker container to your local machine

     #+begin_src bash
       docker cp es01:/usr/share/elasticsearch/config/certs/http_ca.crt .
     #+end_src

  5. Open a new terminal and verify that you can connect to your Elasticsearch cluster by making an authenticated call, using the http_ca.cert file
     Enter the password for the elastic user when prompted

     #+begin_src bash
       curl --cacert http_ca.crt -u elastic https://localhost:9200
       curl --cacert http_ca.crt -u elastic "https://localhost:9200/_cluster/health?pretty"
     #+end_src

+ Enroll additional nodes
+ When you start Elasticsearch for the first time, the instalation process configures a single-node cluster by default
+ This process also generates an enrollment token and prints it to your terminal
+ If you want a ndoe to join an existing cluster, start the new node with the generated enrollment token
+ The enrollment token is valid for 30 minutes
+ If you need to generate a new enrollment token, run the elasticsearch-create-enrollment-token tool on your existing node
+ This tool is available in the Elasticsearch bin directory of the Docker container

  #+begin_src bash
    docker exec -it es01 /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node
  #+end_src

  #+begin_src bash
    docker run -e ENROLLMENT_TOKEN="<token>" --name es02 --net elastic -it docker.elastic.co/elasticsearch/elasticsearch:8.4.3
  #+end_src

+ If you experience issues where the container where your first node is running exists when your second node starts
+ Explicitly set values for the JVM heap size
+ To mannually configure the heap size, include the ES_JAVA_OPTS variable and set values for -Xms and -Xmx when starting each node
+ For example, the following command starts node es02 and sets the minimum and maximum JVM heap size to 1GB

  #+begin_src bash
    docker run -e ES_JAVA_OPTS="-Xms1g -Xmx1g" -e ENROLLMENT_TOKEN="<token>" --name es02 -p 9201:9200 --net elastic -it docker.elastic.co/elasticsearch/elasticsearch:8.4.3
  #+end_src

+ Security certificates and keys
+ When you install Elasticsearch, the following certificates and keys are generated in the Elasticsearch configuration directory
+ They are used to connect a Kibana instance to your secured Elasticsearch cluster and to encrypt internode communication
+ http_ca.crt -> The CA certificate that is used to sign the certificates for the HTTP layer of the Elasticsearch cluster
+ http.p12 -> Keystore that contains the key and certificate for the HTTP layer of this Node
+ transport.p12 -> Keystore that contains the key and certificate for the transport layer for all the nodes in your cluster
+ To retrieve the password use the /bin/elasticsearch-keystore
+ Start a multi-node cluster with Docker Compose
+ You can use Docker compose to get a multi-node Elasticsearch cluster and Kibana up and running in Docker
+ Prepare the environment
+ .env
+ The .env file sets environmnet variables that are used when you run the docker-compose.yml
+ docker-compose.yml
+ Using the Docker images in production
+ The following requirementes and recommendations apply when running Elasticsearch in Docker in production
+ Set vm.max_map_count to at least 262144
+ Configuration files must be readable by the elasticsearch user
+ By default, Elasticsearch runs inside the container as user elasticsearch using uid:gid 1000:0
+ Increase ulimits for nofile and nproc
+ Verify the init system for the Docker daemon sets them to acceptable values
+ To check the docker daemon defaults for ulimits, run

#+begin_src bash
  docker run --rm docker.elastic.co/elasticsearch/elasticsearch:{version} /bin/bash -c 'ulimit -Hn && ulimit -Sn && ulimit -Hu && ulimit -Su'
#+end_src

+ If needed, adjust them in the Daemon or override them per container
+ Disable swapping
+ Swapping needs to be disable for performance and node stability
+ If you opt for the bootstrap.memory_lock: true approach, you also need to define the memlock: true ulimit in the Docker Daemon
+ Or explicitly set for the container

#+begin_src bash
  -e "bootstrap.memory_lock=true" --ulimit memlock=-1:-1
#+end_src

+ Randomize published ports
+ By default the image exposes TCP ports 9200 and 9300
+ For production clusters, randomizing the published ports with --publish--all is recommended
+ Manually set the heap size
+ By default, Elasticsearch automatically sizes JVM heap based on a nodes' roles and the total memory available to the node's container
+ To manually set the heap size in production, bind mount a JVM options file under /usr/share/elasticsearch/config/jvm.options.d
+ For testing you can also manually set the heap size using the ES_JAVA_OPTS
+ For example, to use 16GB specify -e ES_JAVA_OPTS='-Xms16g -Xmx16g'
+ Pin deployments to a specif image version
+ Always bind data volumes
+ You should use a volume bound on /usr/share/elasticsearch/data for the following reasons
  - The data of your Elasticsearch node won't be lost if the container is killed
  - Elasticsearch is I/O sensitive and the Docker storage driver is not ideal for fast I/O
  - It allows the use of advanced Docker volume plugins
+ Avoid using the loop-lvm mode
+ If your are using the devicemapper storage driver, configure docker-engine to use direct-lvm
+ Centralize your logs
+ Considering centralizing your logs by using a different logging driver, the default json-file logging is not ideally suited for production use
+ Configuring Elasticsearch with Docker
+ When you run in Docker, the Elasticsearch configuration files are loaded from /usr/share/elasticsearch/config
+ To use custom configuration files, you bind-mount the files over the configuration files in the image
+ You can set individual Elasticsearch configuration parameters using Docker environment variable
+ You can use the setting name directly as the environment variable name
+ If you cannot do this, for example because your orchestration platform forbids periods in environment variable names, then you can use an alternative style by converting the setting name as follow
  1. Change the setting name to uppercase
  2. Prefix it with ES_SETTING_
  3. Escape any underscores (_) by duplicating them
  4. Convert all periods (.) to underscores (_)
+ For example, -e bootstrap.memory_lock=true becomes -e ES_SETTING_BOOTSTRAP_MEMORY__LOCK=true
+ You can use the contents of a file to set the value of the ELASTIC_PASSWORD or KEYSTORE_PASSWORD, by suffixing the environment variable name with _FILE
+ For example, to set the Elasticsearch bootstrap password from a file, you can bind mount the file and set the ELASTIC_PASSWORD_FILE environment variable to the mount location
  #+begin_src bash
    -e ELASTIC_PASSWORD_FILE=/run/secrets/bootstrapPassword.txt
  #+end_src
+ You can override the default command for the image to pass Elasticsearch configuration parameters as command line options
+ While bind-mounting your configuration files is usually the preferred method in production, you can also create a custom Docker image that contains your configuration
+ Mounting Elasticsearch configuration files
+ Create custom config files and bind-mount them over the corresponding files in the Docker image
+ If you bind-mount a custom elasticsearch.yml file, ensure it includes the network.host: 0.0.0.0
+ Create an encrypted Elasticsearch keystore
+ By default, Elasticsearch will auto-generate a keystore file for secure settings
+ This file is obfuscated but not encrypted
+ Using custom docker images
+ Troubleshoot Docker errors for Elasticsearch
+ elasticsearch.keystore is a directory
+ elasticsearch.keystroe Device or resource busy

*** Run Elasticsearch locally
+ Start Elasticsearch

  #+begin_src bash
    docker network create elastic
    docker pull docker.elastic.co/elasticsearch/elasticsearch:8.4.3
    docker run --name elasticsearch --net elastic -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -t docker.elastic.co/elasticsearch/elasticsearch:8.4.3
  #+end_src

+ Start Kibana
+ Kibana enables you to easily send request to Elasticsearch and analyze, visualize, and manage data interactively

  #+begin_src bash
    docker pull docker.elastic.co/elasticsearch/kibana:8:4:3
    docker run --name kibana --net elastic -p 5601:5601 docker.elastic.co/kibana/kibana:8.4.3
  #+end_src
